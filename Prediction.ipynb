{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qm8aUgxGvFb"
      },
      "source": [
        "# Mount Drive for dataset Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X28YOqbB4-i",
        "outputId": "55ffecef-b3bf-4e4a-ba5d-884049a03500"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey64BUYKGvFh"
      },
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bbSsKf68Ljp",
        "outputId": "2b681206-9fdf-4a55-bd3c-0b7d610e9f00"
      },
      "outputs": [],
      "source": [
        "# !pip install jiwer\n",
        "# !pip install pandas\n",
        "# !pip install tensorflow\n",
        "# !pip install Numpy\n",
        "# !pip install matplotlib\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJHLaooDus0o"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JeMOhRQkus0q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from jiwer import wer\n",
        "\n",
        "import pyaudio\n",
        "import os\n",
        "import wave\n",
        "import librosa\n",
        "# import numpy as np\n",
        "from sys import byteorder\n",
        "from array import array\n",
        "from struct import pack\n",
        "# import tensorflow as tf\n",
        "import argparse\n",
        "import speech_recognition as sr\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qyXXdZlGvFn"
      },
      "source": [
        "# Load The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "H7BraWkVus0t",
        "outputId": "935f87ea-4fa5-4d53-893e-61157196829c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0a43bdd582.wav</td>\n",
              "      <td>২০১৩ সালের নভেম্বরের</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0adf8db423.wav</td>\n",
              "      <td>মাথার বালিশ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0abd11911b.wav</td>\n",
              "      <td>জয়ললিতাকে তৃতীয় ফ্রন্টে চান</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0a533992ec.wav</td>\n",
              "      <td>আগ্রহী হলেন</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>058a0299fd.wav</td>\n",
              "      <td>উদরস্থিত বায়ু</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0a97949561.wav</td>\n",
              "      <td>শুধু আল্লাহকে মানলে</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0a048b8ea0.wav</td>\n",
              "      <td>মানুষের জীবন যাত্রার উপর ছিল</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>05fdb2c6cd.wav</td>\n",
              "      <td>বর্গমূল কে বলা হয়</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0a30e906fa.wav</td>\n",
              "      <td>বেসরকারি খাতের ১৯টি ব্যাংকও</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>05cf127b7e.wav</td>\n",
              "      <td>পুরুষের পরিচয়</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0a34f4a2b8.wav</td>\n",
              "      <td>হেরেই চলেছেন</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             audio                           text\n",
              "0   0a43bdd582.wav           ২০১৩ সালের নভেম্বরের\n",
              "1   0adf8db423.wav                    মাথার বালিশ\n",
              "2   0abd11911b.wav  জয়ললিতাকে তৃতীয় ফ্রন্টে চান\n",
              "3   0a533992ec.wav                    আগ্রহী হলেন\n",
              "4   058a0299fd.wav                 উদরস্থিত বায়ু\n",
              "5   0a97949561.wav            শুধু আল্লাহকে মানলে\n",
              "6   0a048b8ea0.wav   মানুষের জীবন যাত্রার উপর ছিল\n",
              "7   05fdb2c6cd.wav             বর্গমূল কে বলা হয়\n",
              "8   0a30e906fa.wav    বেসরকারি খাতের ১৯টি ব্যাংকও\n",
              "9   05cf127b7e.wav                 পুরুষের পরিচয়\n",
              "10  0a34f4a2b8.wav                   হেরেই চলেছেন"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_path = r\"C:/Users/purek/OneDrive/Desktop/Forkan last semester/Bangla_ASR_Done/Final_project/asr_data/data/asr-bengali-1000/asr_bengali_1000_wav\"\n",
        "wavs_path = data_path\n",
        "metadata_path = r\"C:/Users/purek/OneDrive/Desktop/Forkan last semester/Bangla_ASR_Done/Final_project/asr_data/data/asr-bengali-1000/data.csv\"\n",
        "\n",
        "# print(data_path)\n",
        "# Read metadata file and parse it\n",
        "metadata_df = pd.read_csv(metadata_path, sep=\",\")\n",
        "metadata_df.columns = [\"audio\", \"text\"]\n",
        "metadata_df = metadata_df[[\"audio\", \"text\"]]\n",
        "# print(metadata_df,\": \")\n",
        "metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
        "# print(metadata_df,\"  2 : \")\n",
        "metadata_df.head(11)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data_path = \"\"\n",
        "# def data_gen(data_path):\n",
        "#     data_path = r\"C:\\Users\\purek\\OneDrive\\Desktop\\Forkan last semester\\Bangla_ASR_Done\\gender-recognition-by-voice-master\\asr_data\\data\\asr-bengali-1000\\asr_bengali_1000_wav\"\n",
        "#     wavs_path = data_path\n",
        "#     metadata_path = r\"C:\\Users\\purek\\OneDrive\\Desktop\\Forkan last semester\\Bangla_ASR_Done\\gender-recognition-by-voice-master\\asr_data\\data\\asr-bengali-1000/data.csv\"\n",
        "\n",
        "#     # print(data_path)\n",
        "#     # Read metadata file and parse it\n",
        "#     metadata_df = pd.read_csv(metadata_path, sep=\",\")\n",
        "#     metadata_df.columns = [\"audio\", \"text\"]\n",
        "#     metadata_df = metadata_df[[\"audio\", \"text\"]]\n",
        "#     print(metadata_df,\": \")\n",
        "#     metadata_df = metadata_df.sample(frac=1).reset_index(drop=True)\n",
        "#     print(metadata_df,\"  2 : \")\n",
        "#     metadata_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyvOR01s6Ahp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlJGGWrD6nZo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDEfiKAous0u"
      },
      "source": [
        "# Split the dataset into training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6o4lCKbus0v",
        "outputId": "9d529371-2acb-4fd1-9206-7497256b0669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of the training set: 948\n",
            "Size of the validation set: 49\n"
          ]
        }
      ],
      "source": [
        "split = int(len(metadata_df) * .95)\n",
        "df_train = metadata_df[:split]\n",
        "\n",
        "\n",
        "split2 = int(len(metadata_df) * .05)\n",
        "df_val = metadata_df[:split2]\n",
        "# df_sex = metadata_df[:split2]\n",
        "\n",
        "print(f\"Size of the training set: {len(df_train)}\")\n",
        "print(f\"Size of the validation set: {len(df_val)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_VPc5X561B7"
      },
      "source": [
        "Test_Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "yHhW5ycp6vI-",
        "outputId": "37813f04-f141-4005-a0c3-dcce9c17f8e7"
      },
      "outputs": [],
      "source": [
        "test_path = \"H:/Final_project/asr_data/data/converted test\"\n",
        "wav_path = test_path\n",
        "metadata_path_test = \"H:/Final_project/asr_data/data/test.csv\"\n",
        "\n",
        "print(test_path)\n",
        "# Read metadata file and parse it\n",
        "test_data_df = pd.read_csv(metadata_path_test, sep=\"|\")\n",
        "test_data_df.columns = [\"audio\", \"text\"]\n",
        "test_data_df = test_data_df[[\"audio\", \"text\"]]\n",
        "test_data_df = test_data_df.sample(frac=1).reset_index(drop=True)\n",
        "test_data_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vabhD766viT",
        "outputId": "00b469c8-76a0-40dc-baef-20d8df27d73a"
      },
      "outputs": [],
      "source": [
        "# split3 = int(len(test_data_df) * 1.0)\n",
        "# df_test = test_data_df[:split3]\n",
        "\n",
        "\n",
        "# print(f\"Size of the testing set: {len(df_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOfpvt_5us0w"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "We first prepare the vocabulary to be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBbI17iED_XR",
        "outputId": "5476d61d-7b53-44d9-844a-4a72745e4fc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The vocabulary is: ['', ' ', '।', 'ঁ', 'ং', 'ঃ', 'অ', 'আ', 'ই', 'ঈ', 'উ', 'ঋ', 'এ', 'ঐ', 'ও', 'ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড', 'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ', 'ন', 'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', 'ল', 'শ', 'ষ', 'স', 'হ', '়', 'া', 'ি', 'ী', 'ু', 'ূ', 'ৃ', 'ে', 'ৈ', 'ো', 'ৌ', '্', 'ৎ', 'ড়', 'য়', '০', '১', '২', '৩', '৪', '৫', '৬', '৭', '৮', '৯'] (size =72)\n"
          ]
        }
      ],
      "source": [
        "chars_db_path = r'C:/Users/purek/OneDrive/Desktop/Forkan last semester/Bangla_ASR_Done/Final_project/asr_data/data/chars_75.csv'\n",
        "\n",
        "unique_chars = pd.read_csv(chars_db_path, skip_blank_lines=False)['chars']\n",
        "unique_chars = unique_chars.to_list()\n",
        "\n",
        "# Mapping characters to integers\n",
        "char_to_num = keras.layers.StringLookup(vocabulary=unique_chars, oov_token=\"\")\n",
        "# Mapping integers back to original characters\n",
        "num_to_char = keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")\n",
        "print(\n",
        "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
        "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsA3lXNrus0y"
      },
      "source": [
        "# Spectogram and Label for preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VcXv2y5Uus0z"
      },
      "outputs": [],
      "source": [
        "\n",
        "frame_length = 256\n",
        "frame_step = 160\n",
        "fft_length = 384\n",
        "\n",
        "\n",
        "def encode_single_sample(wav_file, label):\n",
        "    # Read wav file\n",
        "    file = tf.io.read_file(data_path+\"/\"+wav_file)\n",
        "    # Decode the wav file\n",
        "    audio, _ = tf.audio.decode_wav(file)\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    # Change type to float\n",
        "    audio = tf.cast(audio, tf.float32)\n",
        "    # Get the spectrogram\n",
        "    spectrogram = tf.signal.stft(\n",
        "        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n",
        "    )\n",
        "    # Magnitude value\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
        "    # normalization the magnitude\n",
        "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
        "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
        "\n",
        "\n",
        "    ##  Process the label\n",
        "\n",
        "    # Convert label to Lower case\n",
        "    label = tf.strings.lower(label)\n",
        "    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
        "    # Map the characters in label to numbers\n",
        "    label = char_to_num(label)\n",
        "\n",
        "    return spectrogram, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkhkDNIrus00"
      },
      "source": [
        "## Creating `Dataset` objects\n",
        "\n",
        "We create a `tf.data.Dataset` object that yields\n",
        "the transformed elements, in the same order as they\n",
        "appeared in the input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MRqHtzkGus00"
      },
      "outputs": [],
      "source": [
        "batch_size = 5\n",
        "# Define the trainig dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_train[\"audio\"]), list(df_train[\"text\"]))\n",
        ")\n",
        "train_dataset = (\n",
        "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Define the validation dataset\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(df_val[\"audio\"]), list(df_val[\"text\"]))\n",
        ")\n",
        "\n",
        "\n",
        "gender_dataset=validation_dataset\n",
        "\n",
        "validation_dataset = (\n",
        "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .padded_batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJv54F1Ius02"
      },
      "source": [
        "## Model\n",
        "\n",
        "CTC Loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mTaknqzLus03"
      },
      "outputs": [],
      "source": [
        "\n",
        "def CTCLoss(y_true, y_pred):\n",
        "    # Compute the training-time loss value\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzmWFa8Rus03"
      },
      "source": [
        "# ASR model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocaCcZGjus03",
        "outputId": "a69e96a2-f7d5-4097-abcf-6401ce1f8c5b"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GLuYAlMus04"
      },
      "source": [
        "## Decoder & Callback "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "J_bUXRQSus06"
      },
      "outputs": [],
      "source": [
        "# decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # CTC_DECODE\n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for result in results:\n",
        "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(result)\n",
        "    return output_text\n",
        "\n",
        "cnt=0\n",
        "# A callback class to output a few transcriptions during training\n",
        "class CallbackEval(keras.callbacks.Callback):\n",
        "    \"\"\"Displays a batch of outputs after every epoch.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def on_epoch_end(self, epoch: int, logs=None):\n",
        "        # model_name=\"ASR_model_\"+str(cnt)+\".h5\"\n",
        "        # model.save(model_name)\n",
        "        # cnt+=1\n",
        "        predictions = []\n",
        "        targets = []\n",
        "        for batch in self.dataset:\n",
        "            X, y = batch\n",
        "            batch_predictions = model.predict(X)\n",
        "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
        "            predictions.extend(batch_predictions)\n",
        "            for label in y:\n",
        "                label = (\n",
        "                    tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "                )\n",
        "                targets.append(label)\n",
        "        wer_score = wer(targets, predictions)\n",
        "        print(\"-\" * 100)\n",
        "        print(f\"Word Error Rate: {wer_score:.4f}\")\n",
        "        print(\"-\" * 100)\n",
        "        for i in np.random.randint(0, len(predictions), 2):\n",
        "            print(f\"Target    : {targets[i]}\")\n",
        "            print(f\"Prediction: {predictions[i]}\")\n",
        "            print(\"-\" * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5xddTANus07"
      },
      "source": [
        "# Final Model Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ymiaaXcus08",
        "outputId": "5e00f161-279b-4718-c002-a73684dcb44a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"Bangla_ASR\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, None, 193)]       0         \n",
            "_________________________________________________________________\n",
            "expand_dim (Reshape)         (None, None, 193, 1)      0         \n",
            "_________________________________________________________________\n",
            "convolution_1 (Conv2D)       (None, None, 97, 3)       1353      \n",
            "_________________________________________________________________\n",
            "convolution_1_bn (BatchNorma (None, None, 97, 3)       12        \n",
            "_________________________________________________________________\n",
            "convolution_1_relu (ReLU)    (None, None, 97, 3)       0         \n",
            "_________________________________________________________________\n",
            "convolution_2 (Conv2D)       (None, None, 49, 3)       2079      \n",
            "_________________________________________________________________\n",
            "convolution_2_bn (BatchNorma (None, None, 49, 3)       12        \n",
            "_________________________________________________________________\n",
            "convolution_2_relu (ReLU)    (None, None, 49, 3)       0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, None, 147)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 1024)        2030592   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 1024)        0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, None, 1024)        4724736   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 1024)        0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, None, 1024)        4724736   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, 1024)        0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, None, 1024)        4724736   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, None, 1024)        0         \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, None, 1024)        4724736   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, None, 1024)        1049600   \n",
            "_________________________________________________________________\n",
            "dense_1_relu (ReLU)          (None, None, 1024)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, None, 1024)        0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, None, 73)          74825     \n",
            "=================================================================\n",
            "Total params: 22,057,417\n",
            "Trainable params: 22,057,405\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model=tf.keras.models.load_model(\"epoch100.h5\",custom_objects={\"CTCLoss\":CTCLoss})\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EiiOZHmjJuC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFNVDChrGvGJ"
      },
      "source": [
        "#   Plot History of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vJaGey-lGvGK"
      },
      "outputs": [],
      "source": [
        "# # Plot History\n",
        "# def plot_history(history):\n",
        "\n",
        "#     fig, axs = plt.subplots(2)\n",
        "#     # accuracy sublpot\n",
        "#     axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "#     axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "#     axs[0].set_ylabel(\"Accuracy\")\n",
        "#     axs[0].legend(loc=\"lower right\")\n",
        "#     axs[0].set_title(\"Accuracy eval\")\n",
        "\n",
        "#     # error sublpot\n",
        "#     axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "#     axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
        "#     axs[1].set_ylabel(\"Error\")\n",
        "#     axs[1].set_xlabel(\"Epoch\")\n",
        "#     axs[1].legend(loc=\"upper right\")\n",
        "#     axs[1].set_title(\"Error eval\")\n",
        "\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "Q1eDowKzenqB",
        "outputId": "2126a243-2dab-4536-9182-8f358cf30dd3"
      },
      "outputs": [],
      "source": [
        "# pd.DataFrame(history.history).plot(figsize=(8,5))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "cXmTbuReHCG-",
        "outputId": "4a90713c-6376-44ae-acd5-ea9091eabf12"
      },
      "outputs": [],
      "source": [
        "# metrics = history.history\n",
        "# plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
        "# plt.legend(['loss', 'val_loss'])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qO52EE7Gxnt6"
      },
      "outputs": [],
      "source": [
        "# hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "# # save to json:  \n",
        "# # hist_json_file = 'history.json' \n",
        "# with open(hist_json_file, mode='w') as f:\n",
        "#     hist_df.to_json(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_feature(file_name, **kwargs):\n",
        "    mfcc = kwargs.get(\"mfcc\")\n",
        "    chroma = kwargs.get(\"chroma\")\n",
        "    mel = kwargs.get(\"mel\")\n",
        "    contrast = kwargs.get(\"contrast\")\n",
        "    tonnetz = kwargs.get(\"tonnetz\")\n",
        "    X, sample_rate = librosa.core.load(file_name)\n",
        "    if chroma or contrast:\n",
        "        stft = np.abs(librosa.stft(X))\n",
        "    result = np.array([])\n",
        "    if mfcc:\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "        result = np.hstack((result, mfccs))\n",
        "    if chroma:\n",
        "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, chroma))\n",
        "    if mel:\n",
        "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, mel))\n",
        "    if contrast:\n",
        "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, contrast))\n",
        "    if tonnetz:\n",
        "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
        "        result = np.hstack((result, tonnetz))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sex(file_label):\n",
        "\n",
        "    loc_csv=r\"C:/Users/purek/OneDrive/Desktop/Forkan last semester/Bangla_ASR_Done/Final_project/asr_data/data/asr-bengali-1000/data.csv\"\n",
        "    data_loc=r\"C:/Users/purek/OneDrive/Desktop/Forkan last semester/Bangla_ASR_Done/Final_project/asr_data/data/asr-bengali-1000/asr_bengali_1000_wav/\"\n",
        "    df = pd.read_csv(loc_csv, sep=',')\n",
        "    cnt=0\n",
        "    # data_loc=\"\"\n",
        "    for i in range(len(df)):\n",
        "        a=df.iloc[i,0]\n",
        "        b=df.iloc[i,1]\n",
        "        # print(a,\"\\t\",b)\n",
        "        # print(df)\n",
        "        # cnt+=1\n",
        "        if b==file_label:\n",
        "            # print(a,\"\\t\",b)\n",
        "            data_loc+=a\n",
        "            # print(data_loc)\n",
        "            break\n",
        "    # return data_loc\n",
        "    # print(\"Data Loc = \",data_loc)\n",
        "    features = extract_feature(data_loc, mel=True).reshape(1, -1)\n",
        "    modelsex = tf.keras.models.load_model(\"C:/Users/purek/OneDrive/Desktop/Forkan last semester/Bangla_ASR_Done/Final_project/results/model.h5\")\n",
        "    # predict the gender!\n",
        "    male_prob = modelsex.predict(features)[0][0]\n",
        "    # female_prob = 1 - male_prob\n",
        "    # gender = \"male\" if male_prob > female_prob else \"female\"\n",
        "    # print(\"Gender : \", gender)\n",
        "\n",
        "    return male_prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# gender_dataset = (\n",
        "#     gender_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#     .padded_batch(1)\n",
        "#     .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POPugrO0us08"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xnt71t2us09",
        "outputId": "80c04607-055a-42e8-b96f-4c110a80eabd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0748\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : একদমই দেখা যায়নি\n",
            "Prediction: একদমই দেখা যায়নি\n",
            "Sex       : Male:  13.86 %      Female:  86.14 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : তারা এ শিল্পকে নিয়ে\n",
            "Prediction: তারা এ শিল্পকে নিয়ে\n",
            "Sex       : Male:  94.06 %      Female:  5.94 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : হোয়াইট হাউজ\n",
            "Prediction: হোয়াইট হাউজ\n",
            "Sex       : Male:  7.92 %      Female:  92.08 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : সরকারের অনেক সময় লাগছে\n",
            "Prediction: সরকার অনেক সময় লাগছে\n",
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AD01F8EC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Sex       : Male:  94.23 %      Female:  5.77 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : মাথার ওপর দিয়ে\n",
            "Prediction: মাথার ওপর দিয়ে\n",
            "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AD01FE3A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Sex       : Male:  2.45 %      Female:  97.55 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : এ ধরনের গুজব\n",
            "Prediction: এ ধরনের গুজব\n",
            "Sex       : Male:  93.19 %      Female:  6.81 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : সবুজ তরুর পাশে\n",
            "Prediction: সবুজ তরুর পাশে\n",
            "Sex       : Male:  7.43 %      Female:  92.57 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : মানুষের জীবন যাত্রার উপর ছিল\n",
            "Prediction: মনুষের জীবন যাত্রার উপর ছিল\n",
            "Sex       : Male:  7.26 %      Female:  92.74 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : কাজগুলো উপজেলা পরিষদ\n",
            "Prediction: কাজগুলো উপজেলা পরিষদ\n",
            "Sex       : Male:  7.32 %      Female:  92.68 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : দাবি জানিয়েছেন বিজেপি সভাপতি\n",
            "Prediction: দাবি জানিয়েছেন বিজেপি সভাপতি\n",
            "Sex       : Male:  92.46 %      Female:  7.54 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : পূর্বাচল প্রকল্প\n",
            "Prediction: পূর্বাচল প্রকল্প\n",
            "Sex       : Male:  7.51 %      Female:  92.49 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : অমল বোস\n",
            "Prediction: অমলবোস\n",
            "Sex       : Male:  26.58 %      Female:  73.42 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : সবুজ তরুর পাশে\n",
            "Prediction: সবুজ তরুর পাশে\n",
            "Sex       : Male:  7.43 %      Female:  92.57 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : সিনেমার ফাইটিংয়ের দৃশ্যের মতো\n",
            "Prediction: সিেনেমার ফাইটিংয়ের দৃশ্যের মতো\n",
            "Sex       : Male:  6.95 %      Female:  93.05 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : বর্গমূল কে বলা হয়\n",
            "Prediction: বর্গমূল কে বলা হয়\n",
            "Sex       : Male:  93.13 %      Female:  6.87 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : ২০১৩ সালের নভেম্বরের\n",
            "Prediction: ২০১৩ সালের নভেম্বরের\n",
            "Sex       : Male:  7.08 %      Female:  92.92 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : জয়ললিতাকে তৃতীয় ফ্রন্টে চান\n",
            "Prediction: জয়ললিতাকে তৃতীয় ফ্রন্টে চান\n",
            "Sex       : Male:  94.33 %      Female:  5.67 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : মানুষের জীবন যাত্রার উপর ছিল\n",
            "Prediction: মনুষের জীবন যাত্রার উপর ছিল\n",
            "Sex       : Male:  7.26 %      Female:  92.74 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : একটা হিন্দু মন্দির\n",
            "Prediction: একটা হিন্দু মন্দির\n",
            "Sex       : Male:  5.74 %      Female:  94.26 %\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : উৎসব হলো\n",
            "Prediction: উৎসব হলো\n",
            "Sex       : Male:  73.77 %      Female:  26.23 %\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Check results on more validation samples\n",
        "predictions = []\n",
        "targets = []\n",
        "# gender = list()\n",
        "for batch in validation_dataset:\n",
        "    X, y = batch\n",
        "    batch_predictions = model.predict(X)\n",
        "    batch_predictions = decode_batch_predictions(batch_predictions)\n",
        "    predictions.extend(batch_predictions)\n",
        "    # print(\"binary val : \",y)\n",
        "    for label in y:\n",
        "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
        "        targets.append(label)\n",
        "        \n",
        "        \n",
        "wer_score = wer(targets, predictions)\n",
        "print(\"-\" * 100)\n",
        "print(f\"Word Error Rate: {wer_score:.4f}\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "\n",
        "for i in np.random.randint(0, len(predictions), 20):\n",
        "    print(f\"Target    : {targets[i]}\")\n",
        "    print(f\"Prediction: {predictions[i]}\")\n",
        "    male = sex(targets[i])\n",
        "    female=1-male\n",
        "    # print(\"sex        : \",male)\n",
        "    print(\"Sex       : Male: \",format(male*100,\".2f\"),\"%     \" ,\"Female: \",format(female*100,\".2f\"),\"%\")\n",
        "    # print(male)\n",
        "    print(\"-\" * 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPn87bQinm1f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCeVplOgjMO7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Bangla_forkan_asr_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
